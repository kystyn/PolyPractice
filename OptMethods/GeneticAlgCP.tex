\include{latex_header}
\addbibresource{literature.bib}

\begin{document}
\thispagestyle{empty}

\begin{center}

Министерство науки и высшего образования Российской Федерации

Санкт-Петербургский политехнический университет Петра Великого
\vspace{0.4cm}

Институт прикладной математики и механики

Высшая школа прикладной математики и вычислительной физики
\vspace{4cm}

\LARGE{Курсовая работа}

Дисциплина: ``Методы оптимизации''

\vspace{1.4cm}

\large{\textbf{РЕШЕНИЕ ЗАДАЧ ОПТИМИЗАЦИИ С ПОМОЩЬЮ ГЕНЕТИЧЕСКИХ АЛГОРИТМОВ}}
\end{center}

\vspace{4cm}

\newbox{\lbox}
\savebox{\lbox}{\hbox{Родионова Елена Александровна}}
\newlength{\maxl}
\setlength{\maxl}{\wd\lbox}

\hfill\parbox{11cm}{
Студенты:\\
\hspace*{2cm}{Дамаскинский Константин. Глава 4.1} \\
\hspace*{2cm}{Колесник Виктор. Глава 1}\\
\hspace*{2cm}{Пестряков Данил. Главы 2, 3}\\
\hspace*{2cm}{Рыженко Виктор. Глава 4.2}\\
\\Преподаватель:\\
\hspace*{2cm}{доцент ВШПМиВФ, к.ф.м.н.}\\
\hspace*{2cm}{Родионова Елена Александровна}
\\
\\
\hspace*{5cm}\hspace*{-5cm}Группа:\\
\hspace*{2cm}{3630102/70201}\\
}

\vspace{2.8cm}
\begin{center}
Санкт-Петербург,\\
2019
\end{center}


\pagestyle{fancy}
\fancyhf{}
\fancyfoot[C]{\thepage}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}
\tableofcontents
\pagebreak

\newcommand{\defn}[1]{\textbf{\textit{#1}}}

\chapter*{Введение}
\addcontentsline{toc}{chapter}{Введение}
Во все времена умы человека занимал вопрос о том, по каким законам развивается все сущее. В том числе, и живая природа. Работы Чарльза Дарвина, воспринимаемые ныне как данность, в свое время породили множество споров, не утихающих и по сей день. Ведь именно этот именитый британец выдвинул довольно смелое утверждение о том, что в основе эволюционного прцесса лежат всего три вещи: наследственная изменчивость, борьба за существование, естественный отбор. Сколько бы ни разгоралось споров по поводу истинности работ Дарвина, именно эти три принципа красной нитью проходят через теорию построения \defn{генетических алгоритмов}.
Но было бы ошибочно считать, что этот метод появился как нечто само собой разумеющееся. И история его становления как способа решения оптимизационных задач тому подтверждение. Всё началось во второй половине XX века. Его по праву можно назвать веком информатизации и компьютеризации. С повышением вычслительных мощностей у ученых появился инструмент для симуляции эволюционных процессов. В 50-х годах были опубликованы циклы работ с результатами исследований полученных компьютерных моделей. Еще через десятилетие инженеры решили применить эволюционные принципы при решении некоторых прикладных задач. И уже в 70-х годах проводятся конференции, на которых обсуждаются проблемы и достижения в области изучения генетических алгоритмов как способа решения оптимизационных задач.
В данной работе мы рассмотрим лишь общие идеи и подходы к решению задач оптимизации с использованием генетических алгоритмов. В ходе этого рассмотрения будут даны ответы на следующие вопросы:
\begin{enumerate}
\item Какими принципами руководствоваться при выборе размера популяции?
\item Каким образом сохранять размер популяции, если это возможно?
\item Как, исходя из условий задачи, выбрать критерий отбора?
\item Каким образом выбирается функция приспосабливаемости, она же функция цели?
\end{enumerate}
Эту работу можно разбить на следующие части:
\begin{enumerate}
\item Генетические алгоритмы: понятийный аппарат, принцип работы. В этой части будут рассмотрены общие понятия и принципы построения генетических алгоритмов.
\item Модернизация генетических алгоритмов. В этой части будут рассмотрены основные часто встречающиеся проблемы, возникающие при решении задач с использованием генетических алгоритмов, и методы их решения.
\item Преимущества и недостатки генетических алгоритмов. В этой части будут рассмотрены границы применимости генетических алгоритмов. То есть будет дан ответ на вопрос: "Когда и почему стоит или не стоит применять генетические алгоритмы?"
\item Примеры решения задач. В этой части будут поставлены и формализованы две оптимизационные задачи, которые можно решить с применением генетических алгоритмов. Будут приведены их программные реализации.
\end{enumerate}

\chapter{Генетические алгоритмы: понятийный аппарат, принцип работы}
\section{Постановка задачи}
Имеются:
\begin{itemize}
\item \defn{Целевая функция} --  $f(x)$
\item \defn{Множество}, на котором задана функция - $\Omega$
\end{itemize}
Ставится \defn{оптимизационная задача} -- найти такой элемент $x_{\ast}$, для которого выполняется одно из следующих неравенств:
\begin{eqnarray*}
f(x_{\ast}) \leq f(x), \forall x \in \Omega  \textrm{(задача поиска минимума)},
\end{eqnarray*}
\begin{eqnarray*}
f(x_{\ast}) \geq f(x), \forall x \in \Omega  \textrm{(задача поиска максимума)}.
\end{eqnarray*}
В дальнейшем будем считать, что стоит задача \defn{поиска минимума}.

\section{Описание алгоритма}
Генетические алгоритмы (далее ГА) относятся к стохастическим методам решения оптимизационных задач. ГА представляет собой адаптивный поисковый метод, основанный на селекции лучших элементов в популяции, подобно тому, как это происходит в теории Ч. Дарвина.

Введем основные понятия, применяемые в ГА:
\begin{itemize}
	\item \defn{Вектор} -- упорядоченный набор чисел.
	\item \defn{Хромосома} -- вектор из каких-либо чисел. каждая компонента которого (\textit{позиция хромосомы}) называется \defn{геном}. Если вектор хромосомы представляет собой бинарную строку, то говорят о \defn{бинарном генетическом алгоритме}. Если гены хромосомы являются вещественными числами, а их количество равно количеству переменных в целевой функции, то говорят о \defn{генетическом алгоритме вещественного кодирования}. \cite{mathGA}
	\item \defn{Особь} -- вариант решения задачи, состоящий из 1 или нескольких хромосомы.
	\item \defn{Скрещивание (кроссинговер)} -- операция, при которой две хромосомы обмениваются своими частями.
	\item \defn{Мутация} -- случайное изменение одной или нескольких позиций в хромосоме.
	\item \defn{Популяция} -- совокупность особей.
	\item \defn{Пригодность (приспособленность)} -- функция, глобальный экстремум которой является решением задачи.
	\item \defn{Эволюция популяции} -- чередование поколений, в которых хромосомы изменяют свои значения так, чтобы каждое новое поколение наилучшим образом приспосабливалось к внешней среде.
\end{itemize}

Предположим, что оптимизационная задача уже формализована и имеется способ представления решений в виде совокупности генов и хромосом.

Для начала работы ГА генерируем множество случайных особей для начальной популяции. Далее приступаем к процессу размножения: попробуем на основе исходной популяции создать новую, так чтобы пробные решения в новой популяции были бы ближе к искомому экстремуму целевой функции. Критерием приспособленности особи является значение целевой функции: чем оно меньше, тем более приспособленной является особь (при поиске минимума). Следующим шагом в работе ГА являются мутации. Если скрещивание приводит к относительно небольшим изменениям пробных решений, то мутации могут привести к существенным изменениям значений пробных решений. После мутаций необходимо сформировать новую популяцию. Подобные действия повторяются итеративно, тем самым моделируется ``эволюционный процесс''. Через несколько поколений мы получим популяцию из похожих и наиболее приспособленных особей. Наилучшим образом адаптировавшуюся особь и будем считать решением нашей задачи.

Таким образом, генетический алгоритм работает по следующей схеме \cite{algGA}:
\begin{enumerate}
	\item Генерируем начальную популяцию из N особей, размер которой не будет меняться на протяжении работы всего алгоритма.
	\item Выбираем пары особей-родителей оператором выбора родителя.
	\item Проводим скрещивание каждой пары оператором скрещивания, производя 2 потомков.
	\item Проводим мутацию потомков оператором мутации.
	\item Формируем новую популяцию оператором отбора.
	\item Повторяем шаги 2-5 пока не будет достигнут критерий окончания процесса.
\end{enumerate}

Критерием окончания алгоритма может являться заданное количество поколений или \defn{схождение} популяции.

При схождении популяции все особи почти одинаковы и находятся в области некоторого экстремума. Скрещивание практически не изменяет популяцию, а вышедшие из области за счет мутации особи склонны вымирать, так как имеют меньшую приспособленность. Таким образом, схождение популяции обычно означает, что найден либо глобальный экстремум, либо локальный.

\section{Операторы выбора родителей}
Оператор выбора родителей считается эффективным, если он создает возможность перехода из одной подобласти поиска решения в другую. Это повышает вероятность нахождения глобального экстремума целевой функции. Существует несколько подходов к выбору родительских пар. Наиболее распространнеными являются следующие:
\begin{itemize}[label=$\ast$]
	\item \defn{Панмиксия}

При данном методе выбора родителей каждому члену популяции случайным образом ставится в соответствие целое число на отрезке $[1; N]$, где $N$ -- количество особей в популяции. Данное число рассматривается как номер особи, которая примет участие в скрещивании. При таком выборе некоторые особи не будут участвовать в скрещивании, так как попадут в пару с самими собой. А некоторые особи могут участвовать в нескольких скрещиваниях одновременно.
	\item \defn{Инбридинг}

При данном методе первый родитель выбирается случайным образом, а вторым родителем является член популяции, ближайший к первому. \textit{Ближайший} может пониматься, например, в смысле минимального евклидова расстояния между двумя вещественными векторами.
Инбридинг можно охарактеризовать следующим свойством: так как для скрещивания выбираются только ближайшие особи, популяции может разбиться на группы вокруг подозрительных на экстремумы областей.
	\item \defn{Аутбридинг}

Данный метод отличается от инбридинга тем, что второй родитель выбирается максимально удаленным от первого.
Аутбридинг направлен на сдерживание сходимости алгоритма к уже найденным решениям, заставляя алгоритм исследовать новые области.
	\item \defn{Селекция}

При данном методе родителями могут стать лишь те особи, значение приспособленности которых не меньше пороговой величины, например, среднего значения приспособленности по популяции. Такой подход обеспечивает более быструю сходимость алгоритма. Однако для некоторых многомерных задач со сложным ландшафтом целевой функции быстрая сходимость может превратиться в преждевременную сходимость к квазиоптимальному решению. Этот недостаток может быть отчасти скомпенсирован использованием подходящего механизма отбора, который бы ``тормозил'' слишком быструю сходимость алгоритма (к примеру, 10\% следующей популяции выбирать элитарным отбором, а остальные 90\% создавать случайно).
	\item \defn{Турнирный отбор}

Турнирный отбор является вариацией селекции. Из популяции, содержащей $N$ особей, выбирается случайным образом $t$ особей, и лучшая из них записывается в промежуточный массив. Эта операция повторяется $N$ раз. Особи в полученном массиве используются для скрещивания. 
Размер группы особей, отбираемых для одного раунда турнира, часто равен 2. 
Преимуществом данного способа является то, что он не требует дополнительных вычислений.
	\item \defn{Рулеточный отбор}

Рулеточный способ является вариацией селекции. Особи отбираются с помощью $N$ ``запусков'' рулетки, где $N$ - размер популяции. Колесо рулетки содержит по одному сектору для каждого члена популяции. Размер $i$-го сектора пропорционален вероятности попадания в новую популяцию $P(i)$, вычисляемой по формуле:
\begin{eqnarray*}
	P(i) = \frac{f(i)}{\displaystyle \sum\displaylimits_{i=1}^{N} f(i)}
\end{eqnarray*}
где $f(i)$ - пригодность $i$-й особи.
При таком отборе члены популяции с более высокой приспособленностью с большей вероятностью будут чаще выбираться, чем особи с низкой приспособленностью.
\end{itemize}

\section{Операторы скрещивания}
Оператор скрещивания применяют сразу же после оператора отбора родителей для получения новых особей-потомков.
\begin{itemize}[label=$\ast$]
	\item \defn{Дискретная рекомбинация}

Дискретная рекомбинация применяется к хромосомам с вещественными генами. Основными способами дискретной рекомбинации являются собственно дискретная рекомбинация и промежуточная рекомбинация.
	\begin{itemize}[label=$-$]
		\item \textbf{Дискретная рекомбинация}

	Дискретная рекомбинация соответствует обмену генами между особями. Создаются два потомка, каждый ген которых случайно с равной вероятностью выбирается среди двух соответствующих генов в той же позиции у особей-родителей.
		\item \textbf{Промежуточная рекомбинация}

В данном методе предварительно определяется числовой интервал значений генов потомков, который должен содержать значения генов родителей. Потомки создаются по следующему правилу:
\begin{eqnarray*}
	\textrm{Потомок} = \textrm{Родитель 1} + \alpha \ast (\textrm{Родитель 2} - \textrm{Родитель 1}),
\end{eqnarray*}
где множитель $\alpha$ - случайное число на отрезке $[-d; 1 + d], d \geq 0$.
Наиболее оптимальным считается значение $d = 0.25$ \cite{algGA}. Для каждого гена выбирается отдельный множитель. 
	\end{itemize}
	\item \defn{Кроссинговер}

Рекомбинацию бинарных строк принято называть кроссинговером.
	\begin{itemize}[label=$-$]
		\item \textbf{Одноточечный кроссинговер}

Одноточечный кроссинговер моделируется следующим образом. Случайным образом определяется точка разрыва внутри хромосомы, в которой обе хромосомы делятся на две части и обмениваются ими. Такой тип кроссинговера называется одноточечным, так как при нем родительские хромосомы разделяются только в одной случайной точке.
		\item \textbf{Двуточечный кроссинговер}

При двуточечном кроссинговере выбираются 2 точки разреза. Родительские хромосомы обмениваются сегментами, ограниченными двумя точками. В настоящий момент считается, что двуточечный кроссинговер лучше, чем одноточечный. \cite{algGA}
		\item \textbf{Многоточечный кроссинговер}

Для многоточечного кроссинговера выбирается случайно без повторений $m$ точек разреза. Для получения двух потомков родительские особи обмениваются случайно выбранными сегментами, ограниченными точками разреза.
	\end{itemize}
\end{itemize}

\section{Операторы мутации}
Оператор мутации необходим для ``выбивания'' популяции из локального экстремума и защиты от преждевременной сходимости. Это достигается за счет того, что изменяется случайно выбранный ген или несколько генов в хромосоме. Для мутации можно выбирать несколько особей из популяции, причем их число может быть случайным.
\begin{itemize}[label=$\ast$]
	\item \defn{Плотность мутации}

Стратегия мутации с использованием понятия плотности заключается в мутировании каждого гена случайно выбранного потомка с заданной вероятностью. Величину вероятности применения мутации к каждому гену выбирают так, чтобы в среднем мутировало от 1 до 10\% генов.
	\item \defn{Двоичная мутация}

Для особей, кодированных двоичным кодом или кодом Грея, мутация заключается инвертировании случайно выбранного гена.
	\item \defn{Другие виды мутации}

Для особи, представленной последовательностью генов, можно применить следующие операторы мутации: присоединение случайного гена, вставка случайного гена, удаление случайного гена, обмен местами случайно выбранных генов.
\end{itemize}

\section{Операторы отбора}
Оператор отбора необходим для создания новой популяции.
\begin{itemize}[label=$\ast$]
	\item \defn{Отбор усечением}

При отборе усечением используют популяции особей-родителей и особей-потомков, отсортированные по возрастанию значения функции пригодности. Особи выбираются в соответствии с порогом $T \in [0;1]$. Порог определяет, какая доля особей, начиная с самой пригодной, будет принимать участие в отборе. Среди особей, попавших ``под порог'', случайным образом выбирается одна особь и записывается в новую популяцию. Так повторяется $N$ раз, пока размер новой популяции не станет равен старому. Новая популяция будет состоять из особей с высокой пригодностью, причем некоторые особи могут встречаться несколько раз, а самые пригодные могут и не попасть в популяцию.
	\item \defn{Элитарный отбор}

При элитарном отборе используют популяции особей-родителей и особей-потомков. В новую популяцию выбираются $N$ самых пригодных особей. Иногда данный метод комбинируют с другим -- выбирают в новую популяцию 10\% самых пригодных особей, а остальные 90\% выбирают одним из методов селекции. Иногда эти 90\% создают случайно, как на старте алгоритма. Преимуществом данного метода является то, что не допускается потеря лучших решений.
	\item \defn{Отбор вытеснением}

В отборе вытеснением выбор особи в новую популяцию зависит от величины ее пригодности и от того, есть ли уже в формируемой популяции особь с аналогичным хромосомным набором. Из всех особей с одинаковой приспособленностью предпочтение отдается особям с разными генотипами, то есть тем особям, расстояние между которыми максимально. При данном методе не только сохраняются лучшие решения, но и поддерживается генетическое разнообразие. Отбор вытеснением наиболее пригоден для многоэкстремальных задач, при этом имеется возможность кроме глобального экстремума выделить локальные экстремумы, значения которых близки к глобальному.
\end{itemize}

\section{Выбор параметров генетического алгоритма}
Результат работы генетического алгоритма сильно зависит от того, каким образом настроены его параметры \cite{charsGA}. Основными параметрами ГА являются:
\begin{itemize}
	\item[--] длительность эволюции (количество поколений);
	\item[--] размер популяции;
	\item[--] оператор выбора родителей и его параметры;
	\item[--] оператор скрещивания и его параметры;
	\item[--] оператор мутации и его параметры;
	\item[--] оператор отбора и его параметры.
\end{itemize}

Различные параметры ГА влияют на разные аспекты эволюционного поиска. Выделяют два наиболее общих:
\begin{enumerate}
	\item Исследование пространства поиска.
	\item Использование найденных ``хороших'' решений.
\end{enumerate}

Основная цель в настройке параметров ГА и, одновременно, необходимое условие для стабильного получения хороших результатов работы алгоритма – это достижение баланса между исследованием пространства поиска и использованием найденных решений. Взаимосвязь между параметрами генетического алгоритма, а также их влияние на эволюционный процесс носит сложный характер, поэтому подбор параметров нетривиален и определяется конкретной задачей.

Канонический ГА имеет следующие характеристики:
\begin{itemize}
	\item[--] размер популяции - 20-30 особей;
	\item[--] целочисленное кодирование;
	\item[--] все хромосомы имеют одинаковую длину;
	\item[--] рулеточный отбор;
	\item[--] одноточечный кроссинговер;
	\item[--] двоичная мутация;
	\item[--] новое поколение формируется только из особей-потомков.
\end{itemize}

\chapter{Модернизация генетических алгоритмов}

При использовании генетических алгоритмов для решения задач оптимизации могут возникать проблемы преждевременной сходимости. То есть можно попасть в локальный оптимум и не выйти из него, в силу того, что мы исчерпали возможности популяции к увеличению разнообразия потомства. Существует несколько модернизаций генетических алгоритмов, призванных избегать этих проблем. Рассмотрим некоторые из них:

\begin{enumerate}
\item При использовании популяции с малым числом особей гены распространяются слишком быстро, то есть особи становятся слишком похожими. Можно решить эту проблему тремя способами:
	 \begin{itemize}[label=$\ast$]
	\item \defn{Увеличение числа особей}. Это приведет к использованию дополнительной памяти, но метод весьма эффективен при использовании на простых функциях цели.
	\item \defn{Самоадаптация алгоритмов}. Это чаще всего используемый подход. Он позволяет использовать малый размер популяции. Идея основана на изменении значения вероятности мутации в зависимости от скрещивающихся особей, за счёт чего достигается самоуправлемость алгоритма. Такой поход называется \textit{динамическими мутациями}.
	 \item \defn{Создание массива для хранения особей, генотип которых мы утрачиваем во время формирования новых поколений}. Это, как и в первом случае, приведет к использованию дополнительной памяти, но позволит добавлять особей, которые могли быть не очень приспособленными ранее, но способных сейчас дать лучше адаптированное к новым условиям потомство. Или же позволит увеличить количество плохих генов, чтобы выйти из локального оптимума. 
	\end{itemize}
\item Перечисленные выше способы решения проблемы преждевременной сходимости приводят нас к другой -- сохранению размеров популяции. Как видно, не во всех случаях представляется возможным держать константное для всех поколений число особей. Но, как можно заметить, применение подхода с самоадаптирующимися алгоритмами представляется наиболее приемлемым, если мы хотим решить сразу обе проблемы. 
\end{enumerate}
Для полноты картины рассмотрим хотя бы один из таких алгоритмов.
\pagebreak

\subsubsection{Неоднородная мутация}
Если мутирует ген $y_{i}$, то его новое значение $y^{1}_{i}$ случайным образом генерируется на отрезке $[min_{i}; max_{i}]$ следующим образом:

$
y^{1}_{i} = 
\begin{cases}
	\displaystyle y_{i} + \left(max_{i} - y_{i}\right)\left(1 - r^{{\left(\displaystyle1 - \frac{t}{T}\right)}^{b}}\right) &	q = 0 \\
	\displaystyle y_{i} + \left(y_{i} -  min_{i}\right)\left(1 - r^{{\left(\displaystyle 1 - \frac{t}{T}\right)}^{b}}\right) &	q = 1
\end{cases}
$
,

где q случайным образом принимает значения 0 или 1; r - случайное число из диапазона [0; 1]; t - номер поколения; Т - максимальное число поколений; b - некоторый параметр, обусловленный природой задачи; $min_{i}$ и $max_{i}$ - верхняя и нижняя границы для величины $y_{i}$.

\chapter{Преимущества и недостатки генетических алгоритмов}
Для начала рассмотрим ряд \defn{преимуществ} генетических алгоритмов:
\begin{enumerate}
\item Не требуют никакой информации о поведении функции (к примеру, дифференцируемости). Это важное преимущество. Объясняется оно тем, что ГА работают лишь со значениями функции цели в точках-особях.
\item Относительно стойки к попаданию в локальные оптимумы. Ранее обсуждалось, что существуют версии ГА, применяющие самоадаптирующиеся алгоритмы, основная цель которых замедлять сходимость. Это означает, что до выдачи ответа у нас сформируется большее число поколений, что в свою очередь повышает вероятность обойти больше локальных оптимумов.
\item Могут быть использованы при решении обширного класса оптимизационных задач. Как отмечалось ранее, ГА -- это стохастический метод, основанный на эволюционных принципах. Живая природа, подчиняясь тем же самым законам отбирает лучших для некоторых условий особей. Если посмотреть на постановку большинства оптимизационных задач, то там по сути требуется найти лучшее в некотором плане решение. Это наталкивает на мысль, что в большинстве случаев можно установить некоторого рода биекцию между элементами живой природы и элементами задач оптимизации.
\item Чаще всего просты в реализации. Как было сказано в предыдщем пункте, можно установить биекцию между элементами живой природы и элементами задач оптимизации. И чаще всего такие связи практически очевидны.
\item Можно использовать в задачах с изменяющейся средой. Как говорилось ранее, результат работы ГА зависит только от значений функции цели в точках-особях и от количества последних. И если подменить одну целевую функцию на другую по ходу работы алгоритма, то может произойти одна из двух вещей. Либо наши особи окажутся приспособленными к новым условиям, тогда мы быстро получим результат. В противном случае, для новой функции цели наше поколение можно считать сформированным случайным образом. 
\end{enumerate}
Теперь перейдем к \defn{недостаткам}:
\begin{enumerate}
\item Неразумно применять на долго вычисляемых функциях. Отметим, что в современном мире вычислительные мощности постоянно растут. Но время всегда будет дорогостоящим ресурсом. А так как функция цели вычисляется для каждой точки-особи в каждом поколении, работа алгоритма становится чересчур времязатратной, что в некоторых случаях даже может стоить денег.
\item Проблематичность кодирования исходных данных в генетическую форму. Под этой формулировкой кроется сразу несколько проблем. Первая заключается в том, что хоть ГА могут быть использованы при решении широкого круга оптимизационных задач, все же остается та часть, для которой тяжело установить упоминаемую ранее биекцию. Но даже если это оказывается возможным, мы можем столкнуться со второй проблемой. Она заключается непосредственно в самом способе кодирования. Помимо того, что он сам может оказаться достаточно тяжелым и долгим, никто не гарантирует, что на закодированных данных можно проводить быстрые вычисления или что нам хватит памяти для хранения этого массива информации. Причем упрощение модели может обернуться потерей части оптимальных решений.
\item Не дает никаких гарантий. Под этим следует понимать, что выданный ГА ответ не обязательно будет глобальным оптимумом. Причём этот метод не дает никаких критериев проверки. И чем больше локальных оптимумов или изолированных точек у функции, тем больше становится вероятность ошибочного результата.
\end{enumerate}
Обобщая всё выше сказанное, хочется отметить, что ГА не являются универсальным методом решения всех проблем. Хоть этот способ решения оптимизационных задач и подкупает своей простотой, за нее порою приходится платить огромную цену. Потому что, чем проще теория, тем сложнее применить ее на практике. И ГА - прямое тому подтверждение. В решении каждой задачи неизбежно порождаются свои узкие места. И ГА не дают универсального ответа на вопрос, каким образом решать возникающие проблемы. С одной стороны, это дает некоторую степень свободы. С другой, становится затратным по времени строить свой генетический алгоритм для каждой задачи. И если повезет, то построение окажется простым. Но даже эта простота может таить свои опасности, так как она умеет оказывать ряд неблагоприятных эффектов на решение задач, что было рассмотрено в предыдущей главе. И это далеко не единственный случай, когда преимущество может перетекать в недостаток. К примеру, тот факт, что мы можем ничего не знать о функции при использовании ГА, лишает нас гарантий, что по окончании работы будет выдано верное решение.

Таким образом, заключаем, что ГА стоит использовать тогда и только тогда, когда мы можем быстро и легко построить способ кодирования данных в генетической форме, когда совсем ничего неизвестно про функцию цели и нам не нужны гарантии, что полученное, пусть даже с некоторой допустимой погрешностью, решение является глобальным оптимумом.
\chapter{Примеры решения задач}
\section{Задача об оптимальном управлении грузовым составом}
\subsection{Описание проблемы}
Люди часто думают, что управлять поездом проще, чем машиной -- руля же нет, всё едет само по себе. Только за сигналами следи да чаёк попивай.
Однако на деле всё оказывается не так радужно.

При ведении грузового состава машинист сталкивается с целым рядом неординарных задач, требующих адекватной оценки ситуации, быстрой реакции, аналитического склада ума и, зачастую, хорошей интуиции.
Давайте обратим внимание на факторы, влияющие на процесс движения грузового состава.

\begin{enumerate}
\item Длина поезда.

Длина грузового состава может достигать нескольких километров. Из-за этого при изменении скорости движения -- торможении и разгоне -- на автосцепки вагонов, находящихся в начале, середине и конце действуют разные силы.

Представим ситуацию: поезд шёл под уклон, затормозил, а дальше начался затяжной подъём. Машинист собирает схему на тягу, локомотив начинает тянуть за собой поезд.

Первые вагоны уже не удерживаются тормозом, чего нельзя сказать про задние. Таким образом, мы имеем неиллюзорный шанс порвать автосцепку в конце поезда. Локомотивная бригада скорее всего не увидит оторвавшийся хвост состава, что чревато самыми неприятными последствиями.

\item Распределение массы вдоль поезда.

Здесь проблема носит тот же характер, что и в предыдущем пункте: если оставить лёгкие вагоны впереди, а тяжёлые сзади, то при резком старте, скорее всего, произойдёт разрыв там, где кончаются пустые и начинаются гружёные вагоны. Очень нехорошая ситуация может сложиться при входе на подъём с равнинног участка: пусть, скажем, первая половина поезда порожняя, а вторая гружёная. Тогда машинист может, легко втащив на подъём первую половину вполсилы, добавить позиций, чтобы затащить вторую. В такой ситуации та же самая сцепка -- на стыке пустых и гружёных вагонов -- получит просто фантастическую нагрузку.

\item Погодные условия.

Здесь ситуация схожа с той, которую мы наблюдаем при попытке стронуться с места на завязшем в трясине автомобиле -- момент, подводимый к колесу от двигателя, оказывается больше момента, с которым сила трения покоя действует на колесо, и в результате начинается буксование. На железной дороге буксование можно встретить в куда более простых условиях -- достаточно сильного дождя и слишком тяжёлого поезда.

Но если параметры локомотива на этапе сборки состава подбираются таковыми, чтобы он гарантированно мог стронуть с места поезд в любых погодных условиях, то о торможении уже приходится думать машинисту -- если слишком резко ``дать по тормозам'', то начнётся буксование и воздух в магистрали очень быстро закончится. Состав станет неуправляемым.
\end{enumerate}

Описав основные проблемные ситуации, мы обнаружили наиболее уязвимые узлы управления: автосцепка и тормоз.
\footnote{\defn{Кратко о работе поездного тормоза} Принцип работы следующий: воздух закачивается компрессором в тормозные резервуары под большим давлением. При необходимости затормозить воздух с задаваемой машинистом интенсивностью вытравливается из резервуара в общую тормозную магистраль, ответвления от которой подведены непосредственно к тормозным колодкам. Соответственно чем выше давление в магистрали, тем сильнее прижимаются колодки к колесу и тем быстрее происходит торможение. При отпуске тормоза воздух из магистрали выпускается в атмосферу. Одновременно включается компрессор и воздух нагнетается в тормозные резервуары заново. В данной задаче важно, что это достаточно длительная процедура}

\subsection{Постановка задачи}
На вход даются следующие параметры:
\begin{itemize}
\item Максимальная сила тяги, которую способен развить локомотив
\item Предельная нагрузка на автосцепку
\item Погодные условия
\item Предельный коэффициент трения покоя при данных погодных условиях
\item Зависимость силы торможения от давления в магистрали
\item Скорость сброса (набора) воздуха в магистрали в разных положениях тормозного крана
\footnote{Под \textbf{\textit{силой торможения}} будем понимать силу, с которой тормозная колодка прилегает к колесу.}
\item Длина поезда
\item Время прохождения ``тормозной волны'' вдоль одного вагона (время, в течение которого давление ТМ в данном вагоне сравняется с давлением в ТМ соседнего вагона)
\item Распредление массы поезда
\item Профиль пути
\end{itemize}

Требуется предоставить режим движения, при котором будут выполнены следующие условия:
\begin{itemize}
\item Поезд доедет до пункта назначения в целости за наименьшее время
\item На каждый следующий участок пути поезд подходит с максимальным давлением в ТМ и скоростью не выше максимально допустимой
\end{itemize}


Запас топлива считаем неограниченным -- обычно в реальных условиях с этим действительно нет проблем.

Погода в течение всего маршрута следования считается неизменной (ясно, что если погодные условия изменились, можно разбить путь на части, на которых погодные условия постоянны).

\subsection{Формализация}
\subsubsection{Вход}
\begin{itemize}
\item $F_{\text{тяги max}}$ -- предельная сила тяги локомотива, \textit{кН}
\item $F_{\text{СА max}}$ -- предельная нагрузка на автосцепку, \textit{кН}
\item $W$ -- условная единица, характеризующая погодные условия, численно обозначающая степень увлажнённости рельса
\item $\mu_{max}(W)$ -- зависимость предельного коэффициента трения покоя колеса о рельс от погодных условий
\item $F_{br}(P_{\text{ТМ}})$ -- зависимость силы торможения от давления в тормозной магистрали (далее ТМ),

$[F_{br}]=\text{кН}, [P_{\text{ТМ}}]=\text{кПа}$
\item $P_{\text{ТМ max}}, P_{\text{ТМ min}}$ -- максимальное и минимальное допустимые давления в ТМ
\item $V$ -- число вагонов в поезде
\item $l_{\text{в}}$ -- длина вагона, \textit{м}. Полагаем, что все вагоны имеют одинаковую длину
\item $\tau$ -- время распространения тормозной волны вдоль одного вагона,  \textit{с}
\item $v_{\text{ТМ}}(S)=\frac{dP_{ТМ}}{dt}(S)$ -- зависимость скорость стравливания (или набора) воздуха из тормозной магистрали от выбранной машинистом позиции крана S, \textit{кПа/с}, $S=\overline{1,6}$
\item $m(n)$ -- распределение массы поезда от номера вагона, \textit{тонн}, $n=\overline{1, V}$
\item
$\{(v_{max}^{(k)}, \alpha^{(k)}, d^{(k)})^{T}\}_{k=\overline{1, M}}$ -- профиль пути. Задаётся в виде трёхкомпонетных векторов, состоящих из предельной скорости на участке (\textit{км/ч}), угла наклона (\textit{радианы}) и длины (\textit{м}).

\end{itemize}

\subsubsection{Выход}

${(\{U^{(k)}\}^{h}, \{ S^{(k)}\}^{h}, h, N)^{T}}_{k \in \mathbf{N}}$ -- кортеж, состоящий из табличных функций (1,  2 компоненты), заданных на  $\{t_j\}^{h}, j=\overline{1,N}: t_i=hi, t_N=T_0$. Первая компонента соответствует доле от максимальной тяги, а вторая -- позиции тормозного крана. Третья и четвёртая компоненты кортежа -- параметры временной сетки, на которой определены функции.


\subsubsection{Ограничения}

На $k$-ом участке перегона:

$
	\begin{cases}
	\displaystyle \int\displaylimits_{0}^{T_0}{v_{\text{ТМ}}}(t)dt=0 &	(1)\\
	|F_{i}(t)-F_{i-1}(t)| \le F_{\text{СА} max},  \forall i = \overline{2,V} \forall t \in \{t^{h}\} &	(2) \\
	v_{k} + \frac{1}{m(1)} \displaystyle \int\displaylimits_{0}^{T_0}F_{1}(t)dt \le v_{k+1} &	(3) \\
	F_{\text{тяги}}(t) \le F_{\text{тяги max}}, \forall t \in \{t^{h}\} &	(4) \\
	\displaystyle \int\displaylimits_{0}^{T_0}{v(t)}dt = d^{(k)} &	(5) \\
	F_{\text{тяги}}(t) \cdot v_{\text{ТМ}}(t) \le 0 \forall t \in \{t^{h}\} &	(6)
	\end{cases}
$

(1) -- давление в ТМ не должно измениться к концу перегона

(2) -- в каждый момент времени нагрузка на автосцепку не должна превышать предельную

(3) -- скорость на выходе не должна превышать ограничение на следующем участке. Так как все вагоны движутся с одиноковой скоростью, можно не умаляя общности рассматривать первый вагон

(4) -- тепловоз не может развить мощность, б$\acute{\text{о}}$льшую, чем конструкционная

(5) -- за данный промежуток времени тепловоз должен пройти заданное расстояние

(6) -- в каждый момент либо происходит набор воздуха в ТМ вместе с набором тяги, либо торможение с выключенной тягой

Кроме того, для упрощения задачи будем блокировать ручку тормозного крана до тех пор, пока тормозная волна не дойдёт до конца поезда.


\subsubsection{Функция цели}
$T_{0}\rightarrow min$

\subsubsection{Алгоритм решения}

Мы разобьём общую задачу -- нахождение оптимального режима на всём пути -- на подзадачи нахождения оптимального режима на каждом отдельном участке (будем пренебрегать возможными оптимизационными манёврами на стыках профиля ввиду сложности).

Данную задачу концептуально мы будем решать следующим образом.
В генетический алгоритм будет передаваться желаемое время прохождения перегона $T_0$. Алгоритм будет пытаться найти режим движения, в котором поезд сможет благополучно дойти до пункта назначения за данное время. Параметр $T_0$, исходя из результатов работы генетического алгоритма, будет корректироваться по методу половинного деления. Начальный $T_0$ мы найдём аналитически -- вычислим время, за которое поезд гарантированно сможет преодолеть перегон с указанными выше условиями.

Таким образом, наша задача будет решаться связкой генетического алгоритма и метода половинного деления. За счёт такого подхода мы сможем использовать все достоинства ГА и при этом обойти его недостатки: с помощью ГА мы будем отвечать на вопрос, \textbf{\textit{можно ли}} подобрать режим ведения так, чтобы за данное $T_0$ поезд успешно прошёл участок, а не \textbf{\textit{какое $T_0$ оптимальное}.} Сам параметр $T_0$ же будет вычисляться методом половинного деления, сходимость которого нам точно известна.

Мы полагаем, что такой подход лучше, поскольку задавая ГА директивный вопрос: \textbf{\textit{да}} или \textbf{\textit{нет}}, мы имеем более обоснованную надежду на то, что ГА сможет дать корректный ответ, чем задавая вопрос: \textbf{\textit{какое значение оптимально}}, хотя бы потому, что область возможных решений несравнимо меньше. 

\subsection{Выбранные операторы}

\textit{Исходная популяция} сразу генерировалась из соображений выполнения условия $(6)$. При этом генерация производилась таким образом, чтобы этапы тяги и торможения длились значительный промежуток времени, то есть чтобы не было хаотичного ``дёрганья'' контроллера машиниста и тормозного крана.

\textit{Родители} выбирались методом панмиксии, так как исходные особи генерировались практически случайным образом, не подключая никаких соображений здравого смысла, кроме вышеописанного.

\textit{Оператором скрещивания} был выбран двухточечный кроссинговер, с выбором точек в случайном месте хромосомы. Это позволяет создавать из исходных простых режимов управления более сложные последовательности действий.

В качестве \textit{оператора мутации} был выбран следующий механизм: брался какой-то участок, на котором происходит, скажем, разгон, и заменялся на торможение, и наоборот. Такая процедура проделывалась примерно с 10\% особей.

\text{Отбор} производился при помощи модернизированного механизма усечения: из полученных после кроссинговера особей выбиралась половина наиболее приспособленных. Вторая половина же выбиралась случайным образом. Таким образом, мы достигаем такого состояния популяции, когда у нас есть набор ``идущих к успеху'' особей и ``подстраховка'' из ``отстающих'', которые, в случае провала успешных, возможно, смогут исправить ситуацию.

\text{Завершение алгоритма} происходит, как только находится режим управления, в котором поезд, не порвавшись, способен за заданное $T_0$ выйти на следующий участок перегона.

\subsection{Некоторые детали реализации}

\subsubsection{Вычислительные методы}
Расчёт действующих сил и поясняющий рисунок можно найти в разделе \textbf{Приложения}.
Интегрирование заданных величин производилось с помощью квадратурной формулы Ньютона-Котеса первого порядка (метод левых прямоугольников). Эта формула позволяет в данной задаче производить точное интегрирование, так как скорость стравливания давления ТМ,  сила, действующая на вагон и скорость состава являются кусочно-линейными функциями. Соответственно формула с алгебраическим порядком точности 1 по определению считает такие интегралы без погрешности.

Из тех же соображений интегрирование сил и скоростей для вычисления координаты поезда в заданный момент времени производилось тем же методом левых прямоугольников.

\subsubsection{Источники}
Математическая модель движения поезда и принцип действия тормоза: \cite[стр. 2]{charsBM2}, \cite[стр. 42]{charsBM2}.
Числовые характеристики ТМ, автосцепки СА-3 и типовых локомотивов: \cite{Coupler}, \cite{charsBM1}.

\section{Задача круглого раскроя}
\subsection{Описание задачи}
Рассматриваемая задача — поиск рационального плана раскроя плоского листа на предметы круглой формы. Задачи такого рода впервые
были поставлены еще в 1940-х академиком Л.В. Канторовичем. С тех пор появилось большое количество новых постановок и методов решения. Однако существуют практически значимые 
постановки задач и технологические ограничения, для которых решение задачи раскроя и
разработка новых методов решения по-прежнему актуальны.
Вообще, задача плоского раскроя — это оптимизационная задача поиска наиболее плотного размещения множества меньших по размеру 
плоских предметов, деталей, на больших объектах, заготовках

\subsection{Математическая постановка задачи}
Заданы следующие параметры и условия:
\begin{itemize}
\item Полубесконечная полоса ширины $W$ 
\item $n$ круглых деталей
\item Радиусы деталей  $r_{i}, i = \overline{1, n}$
\item Детали попарно не персекаются:

$(x_{i} - x_{j})^{2} + (y_{i} - y_{j})^{2} \ge (r_{i} - r_{j})^{2}, i, j = \overline{1, n}, i \neq j$
\item Детали не выходят за границы полосы: 
$%\begin{equation}
\begin{cases}
	x_{i} - r_{i} \ge 0 \\
	y_{i} - r_{i} \le 0,	& i = \overline{1, n} \\
	y_{i} + r_{i} \le W
\end{cases}
$%\end{equation}
\end{itemize}

Здесь ${(x_{i}, y_{i}),   i = \overline{1, n}}$ - координаты центров деталей

Необходимо разместить детали на полосе так, чтобы занимаемая часть полосы была минимальна, т. е. ${\max\limits_{i = \overline{1, n}}(x_{i} + r_{i})\xrightarrow[{(x_i, y_i)}]{} \min}$
\subsection{Алгоритм решения}
Задача разбивается на два блока: сам генетический алгоритм и декодер.
\subsubsection{Генетический алгоритм}
В качестве особи рассмотрим расположение всех предметов на полосе. Пронумеруем все предметы, и в качестве хромосомы будем считать последовательность полученных чисел, отображающую размещение предметов. Далее предметы выкладываются на полосу в порядке, обозначенном в хромосоме согласно некоторому правилу, которое задаёт декодер. Данная процедура называется \defn{декодированием}. Декодеры могут быть различны и выбираются под определённую задачу. Для данной задачи выбрана следующая последовательность операторов ГА:
\begin{itemize}
\item Мутация
\item Скрещивание
\item Вымирание
\end{itemize}
Рассмотрим подробнее каждый из них.
\paragraph{Мутация}
Выбираются два случайных параметра генома ($(a = 2, b = 5)$) и меняются местами с друг другом (особь $S = (1, 2, 3, 4, 5) $ преобразуется к виду $S = (1, 5, 3, 4, 1)$).
\paragraph{Скрещивание}
Выбираются случайные параметры для первого родителя и размещаются в геноме потомка, затем выбираются параметры второго родителя, которые еще не являются частью генома потомка, и размещаются в оставшейся части генома потомка согласно порядку во втором родителе ($S_{1} = (1, \textbf{2, 5, 4}, 3)$ и $S_{2} = (5, 4, 3, 2, 1)$ порождают потомка $S = (2, 5, 4, 3, 1)$).
\paragraph{Вымирание}
Каждой особи сопоставляется после разложения значение целевой функции ${\max\limits_{i = \overline{1, n}}(x_{i} + r_{i})}$,  упорядочивается и выбирается лучшая половина.
\subsubsection{Декодер}

На вход декодеру поступает последовательность, семантика которой описана выше. Декодер выстраивает объекты ``змейкой'', то есть от верхнего края до нижнего, затем до верхнего и так далее. Каждый объект выставляется как можно плотнее к левому краю. Делается это следующим образом: каждый объект скользит вдоль границы предыдущего объекта к левому краю (координата по $x$ уменьшается, а координата по $y$ расчитывается так, чтобы текущая деталь имела только одну общую точку с предыдущей) до тех пор пока текущая деталь не коснётся любую другую выложенную деталь (поиск этого ``оптимального'' положения получаем при помощи двоичного поиска). Таким образом последовательно на полосу выкладываются все предметы. 

\chapter{Заключение}
Таким образом, генетические алгоритмы являются мощным вычислительным средством для решения разнообразных оптимизационных задач. ГА отличаются от большинства оптимизационных и поисковых методов по следующим пунктам:
\begin{itemize}
	\item ГА оперируют закодированным множеством параметров, а не самими параметрами;
	\item ГА используют популяции точек, а не единственную точку;
	\item ГА не требует производные целевой функции или какие-либо вспомогательные значения;
	\item В ГА применяется вероятностное правило перехода, а не детерминированное.
\end{itemize}

Кроме того, ГА является весьма гибким алгоритмом. Возможность подбирать разные параметры алгоритма не только расширяет класс задач, которые ГА способен решить, но и позволяет ускорять сходимость и повышать точность решения одной и той же задачи.

Однако следует помнить, что правильность решения задачи генетическим алгоритмом не гарантируется. Алгоритм может выдать локальный экстремум или вовсе не сойтись ни к какому экстремуму. Поэтому применять его полезно лишь к тем задачам, для которых нет подходящего специального алгоритма.

\chapter*{Приложения}
\addcontentsline{toc}{chapter}{Приложения}

\begin{enumerate}
\item Ссылка на реализацию алгоритмов и исходный \LaTeX - код данной работы: 

https://github.com/kystyn/PolyPractice/tree/master/OptMethods

\item Расчёт сил в задаче 4.1:

\end{enumerate}



\printbibliography
\addcontentsline{toc}{chapter}{Список литературы}

\end{document}